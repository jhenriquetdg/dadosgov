{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_resources_directory = '../data/raw/universidade_federal_do_rio_grande_do_norte_-_ufrn'\n",
    "proc_resources_directory = '../data/proc/universidade_federal_do_rio_grande_do_norte_-_ufrn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(proc_resources_directory,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_filenames = os.listdir(raw_resources_directory)\n",
    "resources_filepaths = [os.path.join(raw_resources_directory,resource_filename) for resource_filename in os.listdir(raw_resources_directory)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_csv_paths_containing = lambda pattern : [fn for fn in resources_filepaths if len(re.findall(pattern,fn)) and fn.endswith('.csv')]\n",
    "resources_csv_names_containing = lambda pattern : [fn for fn in resources_filenames if len(re.findall(pattern,fn)) and fn.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "componentes = pd.concat([pd.read_csv(fn,sep=';') for fn in resources_csv_paths_containing('componentes-curriculares')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in componentes.iloc:\n",
    "    proc_component_directory = os.path.join(proc_resources_directory,'componentes',c['codigo'])\n",
    "    info_filepath = os.path.join(proc_component_directory,'info.json')\n",
    "    if os.path.exists(info_filepath): continue\n",
    "    os.makedirs(proc_component_directory,exist_ok=True)\n",
    "    with open(info_filepath,'w+') as f:\n",
    "        json.dump(c.to_dict(), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_resource_year_semester = lambda r : ''.join(re.findall('[0-9]',re.findall('[0-9][0-9-\\.]+',r.split('/')[-1])[0])) \n",
    "extract_resource_year          = lambda r : int(extract_resource_year_semester(r)[:4])\n",
    "extract_resource_semester      = lambda r : int(extract_resource_year_semester(r)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame({\n",
    "            'filepath' : resources_csv_paths_containing(pattern),\n",
    "            'filename' : resources_csv_names_containing(pattern),\n",
    "            'ano'     : [extract_resource_year(r) for r in resources_csv_paths_containing(pattern)],\n",
    "            'semestre' : [extract_resource_semester(r) for r in resources_csv_paths_containing(pattern)]\n",
    "        })\n",
    "        for pattern in ['matricula','turma']\n",
    "    ]\n",
    ").sort_values(['ano','semestre','filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (ano, semestre), df_file in df_files.groupby(['ano','semestre']):\n",
    "    if df_file.shape[0] < 2: continue\n",
    "    \n",
    "    df_ano_matriculas = pd.read_csv(\n",
    "        df_file.iloc[0]['filepath'],\n",
    "        sep=';',\n",
    "        decimal=',',\n",
    "        usecols=[\n",
    "            'id_turma',\n",
    "            'discente',\n",
    "            'media_final',\n",
    "            'numero_total_faltas',\n",
    "            'descricao'\n",
    "        ]\n",
    "    ).drop_duplicates()\n",
    "\n",
    "    df_ano_turmas = pd.read_csv(\n",
    "        df_file.iloc[1]['filepath'],\n",
    "        sep=';',\n",
    "        decimal=','\n",
    "    )\n",
    "\n",
    "    for (id_turma,), df_matricula_turma in df_ano_matriculas.groupby(['id_turma']):\n",
    "        \n",
    "        id_aux_turma = df_ano_turmas['id_turma'] == id_turma\n",
    "        df_turma = df_ano_turmas[id_aux_turma]\n",
    "        if df_turma.shape[0] == 0 : continue\n",
    "\n",
    "        id_componente  = df_turma.iloc[0]['id_componente_curricular']\n",
    "        df_componente  = componentes[componentes['id_componente'] == id_componente]\n",
    "        if df_componente.shape[0] == 0 : continue\n",
    "\n",
    "        codigo_componente = df_componente.iloc[0]['codigo']\n",
    "        component_directory = os.path.join(proc_resources_directory,'componentes',codigo_componente)\n",
    "\n",
    "        filename = f'{ano}_{semestre}_{id_turma}.json'\n",
    "        filepath = os.path.join(component_directory,filename)\n",
    "        \n",
    "        if os.path.exists(filepath) : continue\n",
    "        print(filepath)\n",
    "        siape                     = list(df_turma['siape'].values)\n",
    "        matricula_docente_externo = list(df_turma['matricula_docente_externo'].values)\n",
    "        ch_dedicada_periodo       = list(df_turma['ch_dedicada_periodo'].values)\n",
    "        \n",
    "        df_turma = df_turma.loc[:,~df_turma.columns.isin(['siape','matricula_docente_externo','ch_dedicada_periodo'])].drop_duplicates()\n",
    "        \n",
    "        df_turma['siape'] = [siape]\n",
    "        df_turma['matricula_docente_externo'] = [matricula_docente_externo]\n",
    "        df_turma['ch_dedicada_periodo'] = [ch_dedicada_periodo]\n",
    "\n",
    "\n",
    "        df_turma['matriculas'] = [{\n",
    "            'discente'            : list(df_matricula_turma['discente'].values),\n",
    "            'descricao'           : list(df_matricula_turma['descricao'].values),\n",
    "            'media_final'         : list(df_matricula_turma['media_final'].values),\n",
    "            'numero_total_faltas' : list(df_matricula_turma['numero_total_faltas'].values)\n",
    "        }]\n",
    "        \n",
    "        with open(filepath,'w+') as f:\n",
    "            json.dump(df_turma.iloc[0].to_dict(),f,indent=4,cls=NpEncoder)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
